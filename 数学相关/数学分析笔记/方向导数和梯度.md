
# 方向导数和梯度
## 方向导数
我们知道，$f(x,y)的偏导数可以表示为f_{x}(x_{0},y_{0})=\lim_{ \Delta x \to 0 } \frac{f(x_{0}+\Delta x,y_{0})-f(x_{0},y_{0})}{\Delta x}$
以及$f_{y}(x_{0},y_{0})=\lim_{ \Delta x \to 0 } \frac{f(x_{0}+\Delta x,y_{0})-f(x_{0},y_{0})}{\Delta y}$
实际上这是函数$f(x,y)沿着(1,0)与(0,1)方向的变化率，从而一般地，我们可以给出方向导数的定义：$
	*Define:方向导数*
	$$
\begin{gather}
z=f(x,y)\in D是定义在D上的二元函数，(x_{0},y_{0})\in D,\vec{v}=(\cos\alpha,\sin\alpha)是一个方向，若极限 \\
\lim_{ t \to 0 } \frac{f(x_{0}+t\cos\alpha,y_{0}+t\sin\alpha)-f(x_{0},y_{0})}{t} \\
存在，则称此极限为函数f在(x_{0},y_{0})沿\vec{v}的方向导数，记作\frac{ \partial f }{ \partial \vec{v} } (x_{0},y_{0})
\end{gather}
$$
定理：
$若z=f(x,y)在P(x_{0},y_{0})处可微，那该函数在该点沿任意方向的偏导数都存在，且我们有：$
$\frac{ \partial f }{ \partial \vec{v} }=\frac{ \partial f }{ \partial x }\cos\alpha+\frac{ \partial f }{ \partial y }\sin\alpha,其中\vec{v}=(\cos\alpha,\sin\alpha)$
证明如下：
$由于f在P点处可微，从而我们有：$
$f(x_{0}+t\cos\alpha,y_{0}+t\sin\alpha)-f(x_{0},y_{0})=f_{x}(x_{0},y_{0})t\cos\alpha+f_{y}(x_{0},y_{0})t\sin \alpha+o(t)$
$两边除以t并令t\rightarrow0即可得证$
## 梯度
有了方向导数，我们就可以引入梯度的概念
在深度学习或者其它的应用环境中，我们常常需要找到一个多元函数的最小值（或者最大值），一种思路是我们可以沿着函数变化最小（最大）的方向缓慢前进，注意到前进的量可以用$f(x_{0}+t\cos\alpha,y_{0}+t\sin\alpha)-f(x_{0},y_{0})$来表示，$除掉t标准化并令t\rightarrow 0便得到方向导数$
事实上由柯西不等式：$f_{x}\cos\alpha+f_{y}\sin \alpha\leq \sqrt{ (f_{x}^2+f_{y}^2)(\cos^2\alpha+\sin^2\alpha) }=\sqrt{ f_{x}^2 +f_{y}^2}$
$当且仅当\tan\alpha= \frac{f_{y}}{f_{x}}时等号成立$
$记gradf(x_{0},y_{0})=(f_{x}(x_{0},y_{0}),f_{y}(x_{0},y_{0}))$
$注意到此时gradf正好是我们需要的变化最大的方向，我们把这个方向成为f的梯度$
$事实上，记\vec{v}为一方向向量(即|\vec{v}|=1),则\frac{ \partial f }{ \partial \vec{v} }=gradf \cdot\vec{v}显然在\vec{v}与gradf同向时取得最大值，反向时取得最小值$


